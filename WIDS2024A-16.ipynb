{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":73478,"databundleVersionId":8121780,"sourceType":"competition"},{"sourceId":8368511,"sourceType":"datasetVersion","datasetId":4974766},{"sourceId":8479290,"sourceType":"datasetVersion","datasetId":5057258}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:42:39.012498Z","iopub.execute_input":"2024-05-22T14:42:39.013045Z","iopub.status.idle":"2024-05-22T14:42:39.955695Z","shell.execute_reply.started":"2024-05-22T14:42:39.013000Z","shell.execute_reply":"2024-05-22T14:42:39.954646Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"READING TRAIN.CSV AND TEST.CSV\nDF=TRAIN.CSV\nDF1=TEST.CSV","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/dataset/train.csv\")\ndf1=pd.read_csv(\"/kaggle/input/dataset/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:42:39.957275Z","iopub.execute_input":"2024-05-22T14:42:39.957720Z","iopub.status.idle":"2024-05-22T14:42:40.603495Z","shell.execute_reply.started":"2024-05-22T14:42:39.957692Z","shell.execute_reply":"2024-05-22T14:42:40.602358Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"DELETE THE MOST EMPTY COLUMNS IN BOTH TEST AND TRAIN","metadata":{}},{"cell_type":"code","source":"columns_to_drop = ['patient_gender', 'metastatic_first_novel_treatment', 'metastatic_first_novel_treatment_type']\ndf= df.drop(columns_to_drop, axis=1)\ndf.to_csv('TRAIN1.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:42:40.604821Z","iopub.execute_input":"2024-05-22T14:42:40.605148Z","iopub.status.idle":"2024-05-22T14:42:42.243402Z","shell.execute_reply.started":"2024-05-22T14:42:40.605114Z","shell.execute_reply":"2024-05-22T14:42:42.242315Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"columns_to_drop = ['patient_gender', 'metastatic_first_novel_treatment', 'metastatic_first_novel_treatment_type']\ndf1= df1.drop(columns_to_drop, axis=1)\ndf.to_csv('TEST1.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:42:42.246197Z","iopub.execute_input":"2024-05-22T14:42:42.246629Z","iopub.status.idle":"2024-05-22T14:42:43.856235Z","shell.execute_reply.started":"2024-05-22T14:42:42.246588Z","shell.execute_reply":"2024-05-22T14:42:43.855161Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"DISPLAYING EMPTY CELLS IN THE TRAIN AND TEST CSV","metadata":{}},{"cell_type":"code","source":"print(\"\\nMissing values in each column:\")\nprint(df.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:42:43.857409Z","iopub.execute_input":"2024-05-22T14:42:43.857734Z","iopub.status.idle":"2024-05-22T14:42:43.873409Z","shell.execute_reply.started":"2024-05-22T14:42:43.857708Z","shell.execute_reply":"2024-05-22T14:42:43.872200Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\nMissing values in each column:\npatient_id                        0\npatient_race                   6657\npayer_type                     1765\npatient_state                     0\npatient_zip3                      0\n                               ... \nAverage of Sep-18                 7\nAverage of Oct-18                 7\nAverage of Nov-18                12\nAverage of Dec-18                33\nmetastatic_diagnosis_period       0\nLength: 149, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"\\nMissing values in each column:\")\nprint(df1.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:42:43.874563Z","iopub.execute_input":"2024-05-22T14:42:43.874851Z","iopub.status.idle":"2024-05-22T14:42:43.885236Z","shell.execute_reply.started":"2024-05-22T14:42:43.874826Z","shell.execute_reply":"2024-05-22T14:42:43.884208Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"\nMissing values in each column:\npatient_id              0\npatient_race         2785\npayer_type            785\npatient_state           0\npatient_zip3            0\n                     ... \nAverage of Aug-18       7\nAverage of Sep-18       2\nAverage of Oct-18       2\nAverage of Nov-18       8\nAverage of Dec-18      23\nLength: 148, dtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"FILLING IN MISSING VALUES IN TRAIN CSV AND SAVE IN TRAIN1","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndef fill_missing_race(x):\n    mode_values = x.mode()\n    if not mode_values.empty:\n        return x.fillna(mode_values.iloc[0])\n    else:\n        return x.fillna('NANO')\ndf = pd.read_csv('/kaggle/working/TRAIN1.csv')\ndf['patient_race'] = df.groupby('patient_zip3')['patient_race'].transform(fill_missing_race)\nnull_values_race = df[df['patient_race'].isnull()]\nif not null_values_race.empty:\n    print(\"Null values still present in 'patient_race' column after filling.\")\n    print(null_values_race)\nelse:\n    print(\"All null values in 'patient_race' column have been successfully filled.\")\ndf['payer_type'] = df.groupby('patient_zip3')['payer_type'].transform(fill_missing_race)\nnull_values_payer = df[df['payer_type'].isnull()]\nif not null_values_payer.empty:\n    print(\"Null values still present in 'payer_type' column after filling.\")\n    print(null_values_payer)\nelse:\n    print(\"All null values in 'payer_type' column have been successfully filled.\")\ndf.to_csv('TRAIN1.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:42:43.886642Z","iopub.execute_input":"2024-05-22T14:42:43.886935Z","iopub.status.idle":"2024-05-22T14:42:46.899743Z","shell.execute_reply.started":"2024-05-22T14:42:43.886910Z","shell.execute_reply":"2024-05-22T14:42:46.898564Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"All null values in 'patient_race' column have been successfully filled.\nAll null values in 'payer_type' column have been successfully filled.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\ndef fill_missing_race(x):\n    mode_values = x.mode()\n    if not mode_values.empty:\n        return x.fillna(mode_values.iloc[0])\n    else:\n        return x.fillna('NANO')\ndf = pd.read_csv('/kaggle/input/dataset/test.csv')\ndf['patient_race'] = df.groupby('patient_zip3')['patient_race'].transform(fill_missing_race)\nnull_values_race = df[df['patient_race'].isnull()]\nif not null_values_race.empty:\n    print(\"Null values still present in 'patient_race' column after filling.\")\n    print(null_values_race)\nelse:\n    print(\"All null values in 'patient_race' column have been successfully filled.\")\ndf['payer_type'] = df.groupby('patient_zip3')['payer_type'].transform(fill_missing_race)\nnull_values_payer = df[df['payer_type'].isnull()]\nif not null_values_payer.empty:\n    print(\"Null values still present in 'payer_type' column after filling.\")\n    print(null_values_payer)\nelse:\n    print(\"All null values in 'payer_type' column have been successfully filled.\")\ndf.to_csv('TEST1.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:42:46.901079Z","iopub.execute_input":"2024-05-22T14:42:46.901921Z","iopub.status.idle":"2024-05-22T14:42:48.333595Z","shell.execute_reply.started":"2024-05-22T14:42:46.901891Z","shell.execute_reply":"2024-05-22T14:42:48.332254Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"All null values in 'patient_race' column have been successfully filled.\nAll null values in 'payer_type' column have been successfully filled.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"CHECKING THE NULL VALUES AFTER FILLING THEM","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('TRAIN1.csv')\nprint(\"\\nMissing values in each column:\")\nprint(df.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:42:48.337344Z","iopub.execute_input":"2024-05-22T14:42:48.337695Z","iopub.status.idle":"2024-05-22T14:42:48.620069Z","shell.execute_reply.started":"2024-05-22T14:42:48.337666Z","shell.execute_reply":"2024-05-22T14:42:48.618917Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"\nMissing values in each column:\nUnnamed: 0                      0\npatient_id                      0\npatient_race                    0\npayer_type                      0\npatient_state                   0\n                               ..\nAverage of Sep-18               7\nAverage of Oct-18               7\nAverage of Nov-18              12\nAverage of Dec-18              33\nmetastatic_diagnosis_period     0\nLength: 150, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"df1=pd.read_csv('TEST1.csv')\nprint(\"\\nMissing values in each column:\")\nprint(df1.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:42:48.624078Z","iopub.execute_input":"2024-05-22T14:42:48.624365Z","iopub.status.idle":"2024-05-22T14:42:48.742760Z","shell.execute_reply.started":"2024-05-22T14:42:48.624340Z","shell.execute_reply":"2024-05-22T14:42:48.741579Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"\nMissing values in each column:\npatient_id            0\npatient_race          0\npayer_type            0\npatient_state         0\npatient_zip3          0\n                     ..\nAverage of Aug-18     7\nAverage of Sep-18     2\nAverage of Oct-18     2\nAverage of Nov-18     8\nAverage of Dec-18    23\nLength: 151, dtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"FILLING THE ROWS WHICH CANT BE FILLED USING GROUP BY WITH MEAN,MEDIAN OR MODE AS IT HAS INSUFFIECIENT DATA","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/working/TRAIN1.csv')\ncategorical_columns = df.select_dtypes(include=['object']).columns\nfor column in categorical_columns:\n    mode_value = df[column].mode()[0]\n    df[column] = df[column].fillna(mode_value).replace('NANO', mode_value)\nnumerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\nfor column in numerical_columns:\n    median_value = df[column].median()\ndf[column] = df[column].fillna(median_value)\ndf.to_csv('TRAIN1.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:42:48.744479Z","iopub.execute_input":"2024-05-22T14:42:48.744888Z","iopub.status.idle":"2024-05-22T14:42:50.676467Z","shell.execute_reply.started":"2024-05-22T14:42:48.744844Z","shell.execute_reply":"2024-05-22T14:42:50.675251Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/working/TRAIN1.csv')\nprint(\"\\nMissing values in each column:\")\nprint(df.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:42:50.678097Z","iopub.execute_input":"2024-05-22T14:42:50.678439Z","iopub.status.idle":"2024-05-22T14:42:50.921172Z","shell.execute_reply.started":"2024-05-22T14:42:50.678411Z","shell.execute_reply":"2024-05-22T14:42:50.920079Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"\nMissing values in each column:\nUnnamed: 0                      0\npatient_id                      0\npatient_race                    0\npayer_type                      0\npatient_state                   0\n                               ..\nAverage of Sep-18               7\nAverage of Oct-18               7\nAverage of Nov-18              12\nAverage of Dec-18              33\nmetastatic_diagnosis_period     0\nLength: 150, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/input/dataset/test.csv')\ncategorical_columns = df.select_dtypes(include=['object']).columns\nfor column in categorical_columns:\n    mode_value = df[column].mode()[0]\n    df[column] = df[column].fillna(mode_value).replace('NANO', mode_value)\nnumerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\nfor column in numerical_columns:\n    median_value = df[column].median()\n    df[column] = df[column].fillna(median_value)\ndf.to_csv('TEST1.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:42:50.922193Z","iopub.execute_input":"2024-05-22T14:42:50.922470Z","iopub.status.idle":"2024-05-22T14:42:51.817364Z","shell.execute_reply.started":"2024-05-22T14:42:50.922446Z","shell.execute_reply":"2024-05-22T14:42:51.816397Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df1=pd.read_csv('/kaggle/working/TEST1.csv')\nprint(\"\\nMissing values in each column:\")\nprint(df1.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:42:51.818434Z","iopub.execute_input":"2024-05-22T14:42:51.818826Z","iopub.status.idle":"2024-05-22T14:42:51.936864Z","shell.execute_reply.started":"2024-05-22T14:42:51.818791Z","shell.execute_reply":"2024-05-22T14:42:51.935662Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"\nMissing values in each column:\npatient_id           0\npatient_race         0\npayer_type           0\npatient_state        0\npatient_zip3         0\n                    ..\nAverage of Aug-18    0\nAverage of Sep-18    0\nAverage of Oct-18    0\nAverage of Nov-18    0\nAverage of Dec-18    0\nLength: 151, dtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"FILLING IN THE MISSING VALUES IN CATEGORICAL AND NUMERICAL COLUMNS","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/working/TRAIN1.csv')\n\ncategorical_columns = df.select_dtypes(include=['object']).columns\nfor column in categorical_columns:\n    mode_value = df[column].mode()[0]\n    df[column] = df[column].fillna(mode_value)\n\nnumerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\nfor column in numerical_columns:\n    median_value = df[column].median()\n    df[column] = df[column].fillna(median_value)\n\ndf.to_csv('TRAIN1.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:42:51.938303Z","iopub.execute_input":"2024-05-22T14:42:51.938720Z","iopub.status.idle":"2024-05-22T14:42:53.898886Z","shell.execute_reply.started":"2024-05-22T14:42:51.938684Z","shell.execute_reply":"2024-05-22T14:42:53.897613Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf1 = pd.read_csv('/kaggle/working/TEST1.csv')\n\ncategorical_columns = df1.select_dtypes(include=['object']).columns\nfor column in categorical_columns:\n    mode_value = df1[column].mode()[0]\n    df1[column] = df1[column].fillna(mode_value)\n\nnumerical_columns = df1.select_dtypes(include=['float64', 'int64']).columns\nfor column in numerical_columns:\n    median_value = df1[column].median()\n    df[column] = df[column].fillna(median_value)\ndf1.to_csv('TEST1.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:42:53.900257Z","iopub.execute_input":"2024-05-22T14:42:53.900600Z","iopub.status.idle":"2024-05-22T14:42:54.792456Z","shell.execute_reply.started":"2024-05-22T14:42:53.900573Z","shell.execute_reply":"2024-05-22T14:42:54.791381Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"FINDING OUTLIERS AND USING IQR METHOD TO ADJUST THE OUTLIERS AND SAVE IT Back IN TRAIN1.CSV","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndef adjust_outliers_iqr(df, column):\n    Q1 = df[column].quantile(0.25)\n    Q3 = df[column].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    df.loc[df[column] < lower_bound, column] = lower_bound\n    df.loc[df[column] > upper_bound, column] = upper_bound\n    return df\ndf2 = pd.read_csv('/kaggle/working/TRAIN1.csv')\ndf2 = df2.apply(pd.to_numeric, errors='ignore')\nnumeric_columns = df2.select_dtypes(include=['number']).columns\nfor column in numeric_columns:\n    df2 = adjust_outliers_iqr(df2, column)\ndf2.to_csv('TRAIN1.csv', index=False)\nprint(\"Adjusted outliers in the specified columns.\")\nfor column in numeric_columns:\n    Q1 = df2[column].quantile(0.25)\n    Q3 = df2[column].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    outliers = df2[(df2[column] < lower_bound) | (df2[column] > upper_bound)]\n    if not outliers.empty:\n        print(f\"Outliers in {column}:\")\n        print(outliers)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:42:54.793688Z","iopub.execute_input":"2024-05-22T14:42:54.793998Z","iopub.status.idle":"2024-05-22T14:42:57.377647Z","shell.execute_reply.started":"2024-05-22T14:42:54.793972Z","shell.execute_reply":"2024-05-22T14:42:57.376557Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/2506625662.py:13: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n  df2 = df2.apply(pd.to_numeric, errors='ignore')\n/tmp/ipykernel_33/2506625662.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-333700.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n  df.loc[df[column] < lower_bound, column] = lower_bound\n/tmp/ipykernel_33/2506625662.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '24.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n  df.loc[df[column] < lower_bound, column] = lower_bound\n","output_type":"stream"},{"name":"stdout","text":"Adjusted outliers in the specified columns.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\ndef adjust_outliers_iqr(df, column):\n    Q1 = df[column].quantile(0.25)\n    Q3 = df[column].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    df.loc[df[column] < lower_bound, column] = lower_bound\n    df.loc[df[column] > upper_bound, column] = upper_bound\n    return df\ndf2 = pd.read_csv('TEST1.csv')\ndf2 = df2.apply(pd.to_numeric, errors='ignore')\nnumeric_columns = df2.select_dtypes(include=['number']).columns\nfor column in numeric_columns:\n    df2 = adjust_outliers_iqr(df2, column)\ndf2.to_csv('TEST1.csv', index=False)\nprint(\"Adjusted outliers in the specified columns.\")\nfor column in numeric_columns:\n    Q1 = df2[column].quantile(0.25)\n    Q3 = df2[column].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    outliers = df2[(df2[column] < lower_bound) | (df2[column] > upper_bound)]\n    if not outliers.empty:\n        print(f\"Outliers in {column}:\")\n        print(outliers)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:42:57.379086Z","iopub.execute_input":"2024-05-22T14:42:57.379408Z","iopub.status.idle":"2024-05-22T14:42:58.799794Z","shell.execute_reply.started":"2024-05-22T14:42:57.379382Z","shell.execute_reply":"2024-05-22T14:42:58.798774Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/2117461719.py:13: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n  df2 = df2.apply(pd.to_numeric, errors='ignore')\n/tmp/ipykernel_33/2117461719.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-346531.625' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n  df.loc[df[column] < lower_bound, column] = lower_bound\n","output_type":"stream"},{"name":"stdout","text":"Adjusted outliers in the specified columns.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"import pandas as pd\nimport matplotlib.pyplot as plt\ndf2 = pd.read_csv('TRAIN1.csv')\nnumeric_columns = df2.select_dtypes(include=['float64', 'int64'])\nfor column in numeric_columns.columns:\n    plt.figure(figsize=(4,2))\n    df2.boxplot(column=[column])\n    plt.title(f'Boxplot of {column}')\n    plt.xlabel('Values')\n    plt.ylabel(column)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-15T04:22:39.445205Z","iopub.execute_input":"2024-05-15T04:22:39.445482Z","iopub.status.idle":"2024-05-15T04:23:06.087196Z","shell.execute_reply.started":"2024-05-15T04:22:39.445459Z","shell.execute_reply":"2024-05-15T04:23:06.086164Z"}}},{"cell_type":"code","source":"print(\"\\nMissing values in each column:\")\nprint(df.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:42:58.800942Z","iopub.execute_input":"2024-05-22T14:42:58.801236Z","iopub.status.idle":"2024-05-22T14:42:58.824544Z","shell.execute_reply.started":"2024-05-22T14:42:58.801209Z","shell.execute_reply":"2024-05-22T14:42:58.823409Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"\nMissing values in each column:\nUnnamed: 0                     0\npatient_id                     0\npatient_race                   0\npayer_type                     0\npatient_state                  0\n                              ..\nAverage of Sep-18              0\nAverage of Oct-18              0\nAverage of Nov-18              0\nAverage of Dec-18              0\nmetastatic_diagnosis_period    0\nLength: 150, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"\\nMissing values in each column:\")\nprint(df1.isnull().sum())","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-22T14:42:58.825737Z","iopub.execute_input":"2024-05-22T14:42:58.826128Z","iopub.status.idle":"2024-05-22T14:42:58.838309Z","shell.execute_reply.started":"2024-05-22T14:42:58.826091Z","shell.execute_reply":"2024-05-22T14:42:58.837209Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"\nMissing values in each column:\npatient_id           0\npatient_race         0\npayer_type           0\npatient_state        0\npatient_zip3         0\n                    ..\nAverage of Aug-18    0\nAverage of Sep-18    0\nAverage of Oct-18    0\nAverage of Nov-18    0\nAverage of Dec-18    0\nLength: 151, dtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"ML MODELING :CHECKING THE ML MODELS TO FIND THE BEST FIT","metadata":{}},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import ElasticNet, BayesianRidge, PassiveAggressiveRegressor, HuberRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor, AdaBoostRegressor, HistGradientBoostingRegressor\n\n\ndf = pd.read_csv('TRAIN1.csv')\ndf1 = pd.read_csv('TEST1.csv')\n\nX_train = df.drop(columns=[\"metastatic_diagnosis_period\"])\ny_train = df[\"metastatic_diagnosis_period\"]\n\nnumerical_cols = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns\ncategorical_cols = X_train.select_dtypes(include=[\"object\"]).columns\n\nnumerical_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n    (\"scaler\", StandardScaler())\n])\n\ncategorical_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", numerical_transformer, numerical_cols),\n        (\"cat\", categorical_transformer, categorical_cols)\n    ])\n\nmodels = {\n    \"Linear Regression\": LinearRegression(),\n    \"Ridge Regression\": Ridge(),\n    \"Lasso Regression\": Lasso(),\n    \"KNeighbors Regression\": KNeighborsRegressor(),\n    \"Decision Tree Regression\": DecisionTreeRegressor(),\n    \"Random Forest Regression\": RandomForestRegressor(n_estimators=100, random_state=42),\n    \"Gradient Boosting Regression\": GradientBoostingRegressor(),\n    \"SVR\": SVR(),\n    \"ElasticNet Regression\": ElasticNet(),\n    \"Bayesian Ridge Regression\": BayesianRidge(),\n    \"Passive Aggressive Regression\": PassiveAggressiveRegressor(),\n    \"Huber Regressor\": HuberRegressor(),\n    \"Extra Trees Regression\": ExtraTreesRegressor(n_estimators=100, random_state=42),\n    \"AdaBoost Regression\": AdaBoostRegressor(n_estimators=100, random_state=42),\n    \"HistGradientBoosting Regression\": HistGradientBoostingRegressor(random_state=42)\n}\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n\nmodel_errors = {}\n\nall_rmse = {}\n\nfor model_name, model in models.items():\n    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor),\n                               (\"model\", model)])\n    \n    pipeline.fit(X_train, y_train)\n\n    y_pred = pipeline.predict(X_val)\n\n    rmse = mean_squared_error(y_val, y_pred, squared=False)\n\n    all_rmse[model_name] = rmse\n\n    if rmse < 20:\n        model_errors[model_name] = rmse\n\nprint(\"All RMSE values:\")\nfor model, error in all_rmse.items():\n    print(f\"{model}: RMSE = {error}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-17T10:09:13.992108Z","iopub.execute_input":"2024-05-17T10:09:13.992682Z","iopub.status.idle":"2024-05-17T10:14:24.127167Z","shell.execute_reply.started":"2024-05-17T10:09:13.992651Z","shell.execute_reply":"2024-05-17T10:14:24.126323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom catboost import CatBoostRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.neural_network import MLPRegressor\nimport pandas as pd\n\ndf = pd.read_csv('TRAIN1.csv')\ndf1 = pd.read_csv('TEST1.csv')\n\nX_train = df.drop(columns=[\"metastatic_diagnosis_period\"])\ny_train = df[\"metastatic_diagnosis_period\"]\n\nnumerical_cols = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns\ncategorical_cols = X_train.select_dtypes(include=[\"object\"]).columns\n\nnumerical_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n    (\"scaler\", StandardScaler())\n])\n\ncategorical_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", numerical_transformer, numerical_cols),\n        (\"cat\", categorical_transformer, categorical_cols)\n    ])\n\nmodels = {\n    \"CatBoost\": CatBoostRegressor(verbose=0),\n    \"XGBoost\": XGBRegressor(),\n    \"LightGBM\": LGBMRegressor(),\n    \"MLP\": MLPRegressor()\n}\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n\nmodel_errors = {}\n\nall_rmse = {}\n\nfor model_name, model in models.items():\n    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor),\n                               (\"model\", model)])\n\n    pipeline.fit(X_train, y_train)\n\n    y_pred = pipeline.predict(X_val)\n\n    rmse = mean_squared_error(y_val, y_pred, squared=False)\n\n    all_rmse[model_name] = rmse\n\n    if rmse < 20:\n        model_errors[model_name] = rmse\n\nprint(\"All RMSE values:\")\nfor model, error in all_rmse.items():\n    print(f\"{model}: RMSE = {error}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-17T10:34:13.238731Z","iopub.execute_input":"2024-05-17T10:34:13.239150Z","iopub.status.idle":"2024-05-17T10:35:13.902127Z","shell.execute_reply.started":"2024-05-17T10:34:13.239117Z","shell.execute_reply":"2024-05-17T10:35:13.900878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"IN THE ABOVE TWO CELLS WE CAME ACROSS HistGradientBoostingRegressor WITH THE LEAST RMSE VALUE.\nHENCE USING HistGradientBoostingRegressor ML MODEL FOR PREDICTION","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.ensemble import HistGradientBoostingRegressor\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\ntrain_df = pd.read_csv('/kaggle/working/TRAIN1.csv')\ntest_df = pd.read_csv('/kaggle/working/TEST1.csv')\n\nif 'Unnamed: 0' in train_df.columns:\n    train_df.drop(columns=['Unnamed: 0'], inplace=True)\n\nif 'Unnamed: 0' in test_df.columns:\n    test_df.drop(columns=['Unnamed: 0'], inplace=True)\n\nX_train = train_df.drop(columns=[\"metastatic_diagnosis_period\"])\ny_train = train_df[\"metastatic_diagnosis_period\"]\n\ncategorical_cols = X_train.select_dtypes(include=[\"object\"]).columns\ncategorical_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\nnumerical_cols = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns\nif 'Unnamed: 0' in numerical_cols:\n    numerical_cols = numerical_cols.drop('Unnamed: 0')\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', 'passthrough', numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\nmodel = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('regressor', HistGradientBoostingRegressor())\n])\n\nmodel.fit(X_train, y_train)\n\npredictions = model.predict(test_df)\n\nsolution_df = pd.DataFrame({'patient_id': test_df['patient_id'], 'metastatic_diagnosis_period': predictions})\n\nsolution_df.to_csv('solutionhist.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T10:08:33.715970Z","iopub.status.idle":"2024-05-17T10:08:33.716750Z","shell.execute_reply.started":"2024-05-17T10:08:33.716461Z","shell.execute_reply":"2024-05-17T10:08:33.716484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"USING GRADIENTBOOSTINGREGRESSOR MODEL","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\ntrain_df = pd.read_csv('/kaggle/working/TRAIN1.csv')\ntest_df = pd.read_csv('/kaggle/working/TEST1.csv')\n\nif 'Unnamed: 0' in train_df.columns:\n    train_df.drop(columns=['Unnamed: 0'], inplace=True)\n\nif 'Unnamed: 0' in test_df.columns:\n    test_df.drop(columns=['Unnamed: 0'], inplace=True)\n\nX_train = train_df.drop(columns=[\"metastatic_diagnosis_period\"])\ny_train = train_df[\"metastatic_diagnosis_period\"]\n\ncategorical_cols = X_train.select_dtypes(include=[\"object\"]).columns\ncategorical_transformer = Pipeline(steps=[\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\nnumerical_cols = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns\nif 'Unnamed: 0' in numerical_cols:\n    numerical_cols = numerical_cols.drop('Unnamed: 0')\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', 'passthrough', numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\nmodel = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('regressor', GradientBoostingRegressor())\n])\n\nmodel.fit(X_train, y_train)\n\npredictions = model.predict(test_df)\n\nsolution_df = pd.DataFrame({'patient_id': test_df['patient_id'], 'metastatic_diagnosis_period': predictions})\n\nsolution_df.to_csv('solutiongrad.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T10:08:33.718120Z","iopub.status.idle":"2024-05-17T10:08:33.718897Z","shell.execute_reply.started":"2024-05-17T10:08:33.718638Z","shell.execute_reply":"2024-05-17T10:08:33.718660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/working/solutionhist.csv')\ndf.dtypes","metadata":{"execution":{"iopub.status.busy":"2024-05-17T10:08:33.720212Z","iopub.status.idle":"2024-05-17T10:08:33.720958Z","shell.execute_reply.started":"2024-05-17T10:08:33.720695Z","shell.execute_reply":"2024-05-17T10:08:33.720718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/working/solutiongrad.csv')\ndf.dtypes","metadata":{"execution":{"iopub.status.busy":"2024-05-17T10:08:33.722297Z","iopub.status.idle":"2024-05-17T10:08:33.723029Z","shell.execute_reply.started":"2024-05-17T10:08:33.722774Z","shell.execute_reply":"2024-05-17T10:08:33.722795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('/kaggle/working/solutionhist.csv')\n\ndf['patient_id'] = df['patient_id'].astype(int)\ndf['metastatic_diagnosis_period'] = df['metastatic_diagnosis_period'].astype(int)\n\ndf.to_csv('/kaggle/working/solutionhist.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T10:08:33.724471Z","iopub.status.idle":"2024-05-17T10:08:33.725199Z","shell.execute_reply.started":"2024-05-17T10:08:33.724941Z","shell.execute_reply":"2024-05-17T10:08:33.724963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}